{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2.1. Аргументы\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "В данном задании Вам предлагается дописать код решения задачи бинарной классификации на основе классификатора KNN. Шаблон кода приведён Вам в качестве входных данных, Вам необходимо дополнить его так, чтобы алгоритм K ближайших соседей был настроен в следующей конфигурации:\n",
    "\n",
    "- В качестве K должно быть выбрано значение 8\n",
    "- В качестве метрики должно быть использовано манхэттенское расстояние\n",
    "\n",
    "Для обучения модели разобьём выборку на тренировочную и тестовую при помощи функции train_test_split из модуля sklearn.model_selection. Подробнее об этой функции можно прочитать в [официальной документации sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html): \n",
    "\n",
    "Настройте разбиение на тестовую и тренировочную выборку таким образом, чтобы 0.3 объектов попали в тестовую выборку.\n",
    "\n",
    "Оцените качество классификации на тестовой выборке при помощи [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) (функция подсчета доли правильных ответов из sklearn.metrics)\n",
    "\n",
    "В качестве ответа укажите полученное качество на тестовой выборке, округлив ответ **вниз** до сотых."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9766081871345029\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_seed = 4238\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=8, p=1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примечания\n",
    "\n",
    "1. **Не меняйте значение random_state и random_seed!** Это может привести к неправильным ответам.\n",
    "\n",
    "2. Ответ должен быть записан в виде десятичной дроби через **точку** с двумя значащими цифрами. *Например: 0.11*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оптимальная метрика\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "В этом задании Вам предлагается подобрать оптимальную метрику и оптимальное значение гиперпараметра K из диапазона [1,50] для решения задачи классификации на примере датасета Ирисов Фишера. Этот датасет можно загрузить из модуля sklearn.datasets.\n",
    "\n",
    "Качества оценивается при помощи метрики accuracy при помощи методики кросс-валидации. Об этой методике можно подробнее прочитать в [документации sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html).\n",
    "\n",
    "Мы предлагаем Вам заполнить недостающие команды в следующем скелете кода и разобраться, какую метрику оптимально применять для решения данной задачи. В ответе на задание необходимо указать эту метрику.\n",
    "\n",
    "Попробуйте 3 варианта: манхэттенское расстояние, евклидово расстояние и косинусное расстояние. Полный список возможных метрик можно посмотреть по [ссылке](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.distance_metrics.html#sklearn.metrics.pairwise.distance_metrics). Меняйте этот параметр, изменяя значение аргумента `metric` при создании объекта класса `KNeighborsClassifier`. Найдите пару \"метрика\"-\"K\", для которой получается наилучшее качество и в качестве ответа укажите **найденную метрику**\n",
    "\n",
    "**Замечание**: параметр *n_splits* - это количество разбиений `cv` в кросс-валидации. В качестве итоговой метрики берётся усреднение полученных значений метрик по всем разбиениям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best metric: euclidean, Best k: 4, Best score: 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "random_seed = 4238\n",
    "\n",
    "np.random.seed(random_seed)\n",
    "n_splits = 3\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "\"\"\"\n",
    "  Здесь Вам предлагается написать тело цикла для подбора оптимального K\n",
    "  Результаты оценки алгоритма при каждом отдельно взятом K рекомендуем записывать в список cv_scores\n",
    "\"\"\"\n",
    "\n",
    "metrics = [\"manhattan\", \"euclidean\", \"cosine\"]\n",
    "cv_scores = []\n",
    "best_score  = -1000\n",
    "best_k      = -1\n",
    "best_metric = None\n",
    "\n",
    "for metric in metrics:\n",
    "  for k in range(1, 51):\n",
    "      \n",
    "      clf = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "\n",
    "      scores = cross_val_score(clf, X, y, cv=n_splits)\n",
    "      mean_score = np.mean(scores)\n",
    "      cv_scores.append(mean_score)\n",
    "\n",
    "      if mean_score > best_score:\n",
    "            best_score = mean_score\n",
    "            best_k = k\n",
    "            best_metric = metric\n",
    "      # clf.fit(X_train, y_train)\n",
    "      # predictions = clf.predict(x_test)\n",
    "      # acc = accuracy_score(y, predictions)\n",
    "      # cv_scores.append(acc)\n",
    "\n",
    "print(f\"\\nBest metric: {best_metric}, Best k: {best_k}, Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "В этом задании Вам предлагается написать класс `KNN_classifier`, пригодный для решения задачи классификации (многоклассовой).\n",
    "\n",
    "Мы предлагаем Вам шаблон класса. В этом шаблоне заполните тела функций `.fit` и `.predict`\n",
    "\n",
    "В качестве функции близости используйте Евклидово расстояние между объектами (подробнее https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html).\n",
    "\n",
    "Напоминание:\n",
    "\n",
    "* Функция `.fit(x, y)` производит обучение модели. В рамках этой функции необходимо реализовать подбор оптимальных параметров модели/сконфигурировать модель для дальнейшего использования на основе данной тренировочной выборки, где x - это матрица признакового описания выборки, а y - вектор ответов.\n",
    "\n",
    "* Функция `.predict(x)` осуществляет предсказание для каждого из объектов, чьи векторные описания представлены строками матрицы x. Выполняется строго после `.fit()`. Ради безопасности можно даже реализовать механизм отказа в виде выбрасывания специальной ошибки `UnfittedError` в случае попытки вызова функции `.predict()` до вызова функции `.fit()`.\n",
    "\n",
    "Замечание: не изменяйте названия класса и его методов. Это приведёт к ошибке при исполнении Вашего кода в процессе проверки задания. Тем не менее, Вы можете дописать свои собственные методы, если это необходимо.\n",
    "\n",
    "Шаблон класса:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача 2.3. KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class KNN_classifier:\n",
    "    def __init__(self, n_neighbors: int, **kwargs):\n",
    "        self.K = n_neighbors\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, x: np.array, y: np.array):\n",
    "        \"\"\"\n",
    "        Сохраняет обучающие данные.\n",
    "        \n",
    "        Параметры:\n",
    "        x (np.array): Массив признаков размерности n x m, где n - количество объектов, m - количество признаков.\n",
    "        y (np.array): Массив меток размерности n.\n",
    "        \"\"\"\n",
    "        self.X_train = np.array(x)\n",
    "        self.y_train = np.array(y)\n",
    "\n",
    "    def predict(self, x: np.array):\n",
    "        \"\"\"\n",
    "        Предсказывает метки для входных данных.\n",
    "        \n",
    "        Параметры:\n",
    "        x (np.array): Массив признаков размерности k x m, где k - количество объектов, m - количество признаков.\n",
    "        \n",
    "        Возвращает:\n",
    "        np.array: Массив предсказанных меток размерности k.\n",
    "        \"\"\"\n",
    "        if self.X_train is None or self.y_train is None:\n",
    "            raise ValueError(\"Модель не обучена. Сначала вызовите метод fit.\")\n",
    "\n",
    "        predictions = []\n",
    "        for sample in x:\n",
    "            # Вычисляем Евклидово расстояние между текущим объектом и всеми объектами обучающей выборки\n",
    "            distances = np.linalg.norm(self.X_train - sample, axis=1)\n",
    "            # Находим индексы K ближайших соседей\n",
    "            nearest_indices = np.argsort(distances)[:self.K]\n",
    "            # Получаем метки ближайших соседей\n",
    "            nearest_labels = self.y_train[nearest_indices]\n",
    "            # Определяем наиболее часто встречающуюся метку\n",
    "            unique_labels, counts = np.unique(nearest_labels, return_counts=True)\n",
    "            predicted_label = unique_labels[np.argmax(counts)]\n",
    "            predictions.append(predicted_label)\n",
    "        \n",
    "        predictions = np.array(predictions)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Примечания\n",
    "\n",
    "1. Вы можете проверить правильность выполнения задания посредством сравнения полученных результатов с функцией из соответствующего модуля `sklearn`.\n",
    "\n",
    "2. В рамках выполнения данного задания **запрещено** использовать функции из пакета `sklearn` и любого другого, кроме `numpy`. Код, использующий любые другие модули, не пройдёт тесты.\n",
    "\n",
    "3. **Подсказка:** если Вы испытываете сложности с реализацией этого задания, начните выполнять его с написания функции `.predict`. В процессе написания этой функции Вы поймёте, что конкретно Вам требуется получить от обучающей выборки, какую информацию и в каком видед извлечь из неё. Затем реализуйте это в функции `.fit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример входных и выходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    [ 0.56510722,  0.68599596, -0.92388505, -0.29546048, -0.12437532],\n",
    "    [-0.79617537,  0.98406791,  1.19542652, -0.05626863, -0.69868076],\n",
    "    [ 0.9629688 , -1.00423925, -0.53842833, -0.23744358,  0.83226685],\n",
    "    [ 0.24671269, -0.41624448,  0.81679337,  1.59227446,  0.16192583],\n",
    "    [-0.36972363,  0.17425997,  1.33668078,  1.16687907,  0.31709134],\n",
    "    [-1.30482844, -0.05354323, -0.88862186, -1.121785  , -0.78442809],\n",
    "    [-0.53975018,  0.90074877, -1.09317408,  1.52989481, -0.43375015],\n",
    "    [-0.64709803, -0.09775791,  1.3506503 , -1.46957788,  1.63325543],\n",
    "    [-0.73858464, -0.60678229,  0.31420272, -0.43100129, -0.37665876],\n",
    "    [-0.29208809, -0.68795722,  0.06586655,  0.9583851 ,  1.70640775]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNN_classifier(n_neighbors=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = [\n",
    "    [-0.12489725,  0.65791923, -0.73112495,  1.42660225,  1.64728976],\n",
    "    [ 0.01913388, -1.11351208, -0.63244098, -0.98121107,  0.38060892],\n",
    "    [-0.92074931,  1.39812225,  0.39692147,  0.7717827 ,  0.44604002]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(x_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vega",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
