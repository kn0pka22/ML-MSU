{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3pPZpuKiGnI"
      },
      "source": [
        "# 7.1. Разнообразие\n",
        "\n",
        "Как известно, для формирования случайного леса необходимо разнообразие каждого из решающих деревьев в его составе. Добиться такого разнообразия можно как при помощи варьирования параметров деревьев, так и при помощи варьирования обучающих выборок. Это обычно делается при помощи комбинирования методов случайных подпространств и беггинга. Метод случайных подпространств состоит в случайном выборе подмножества признаков. Бэггинг - это техника отбора подмножества объектов из исходной выборки, которая состоит в последовательном случайном выборе объектов выборки [**с возвращением**](https://ru.wikipedia.org/wiki/Размещение#Размещение_с_повторениями).\n",
        "\n",
        "Для ясности приведём следующий пример:\n",
        "\n",
        "Пусть  наша выборка - это черный мешок с пронумерованными шарами. Каждый шар символизирует некоторый объект нашей выборки с соответствующим номером. Процедура бэггинга предлагает нам последовательно хорошо перемешав шары в мешке вытаскивать их один за другим не глядя, записывать их номера на лист бумаги, а затем возвращать их назад в мешок, повторяя эту операцию столько раз, сколько объектов содержится в нашей выборке. Затем мы вынем из мешка все те шары, номер которых хотя бы раз возник в нашем списке. Понятно, что скорее всего среди этих номеров будут повторяющиеся, то есть какие-то шары мы вытянем несколько раз, а какие-то - вообще ни разу. Именно поэтому наша подвыборка и получится случайной. Статистически обоснована оценка того, какой процент шаров из исходной выборки в среднем попадёт в итоговую подвыборку. Эта оценка приблизительно равна $62\\%$.\n",
        "\n",
        "Ваша задача - написать реализацию трёх функций и объединить их в класс `sample`, возвращающий по выборке некоторую случайную подвыборку, пригодную для обучения  одного из деревьев в ансамбле случайного леса.\n",
        "\n",
        "**Замечание:** обратите внимание, что объекты в итоговой подвыборке не должны дублироваться. Мы предлагаем Вам ознакомиться с функциями [np.random.choice](https://numpy.org/doc/stable/reference/random/generated/numpy.random.choice.html) и [np.unique](https://numpy.org/doc/stable/reference/generated/numpy.unique.html), они могут оказаться полезны при выполнении этого задания.\n",
        "\n",
        "Подробнее об этом методе можно прочитать в нашей [лекции](https://colab.research.google.com/drive/1LrqEyfmOKJQdvgxZ56qPcJ_YjJFnP_Ka#scrollTo=kYjii_stqfJo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juW_Uoo_ic0z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class sample(object):\n",
        "    def __init__(self, X, n_subspace):\n",
        "        self.idx_subspace = self.random_subspace(X, n_subspace)\n",
        "\n",
        "    def __call__(self, X, y):\n",
        "        idx_obj = self.bootstrap_sample(X)\n",
        "        X_sampled, y_sampled = self.get_subsample(X, y, self.idx_subspace, idx_obj)\n",
        "        return X_sampled, y_sampled\n",
        "\n",
        "    @staticmethod\n",
        "    def bootstrap_sample(X):\n",
        "        \"\"\"\n",
        "        Возвращает массив индексов объектов, выбранных с помощью бэггинга (с возвращением)\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        idx = np.random.choice(np.arange(n_samples), size=n_samples, replace=True)\n",
        "        return np.unique(idx) \n",
        "\n",
        "    @staticmethod\n",
        "    def random_subspace(X, n_subspace):\n",
        "        \"\"\"\n",
        "        Возвращает массив индексов случайно выбранных признаков (без повторений)\n",
        "        \"\"\"\n",
        "        n_features = X.shape[1]\n",
        "        return np.random.choice(np.arange(n_features), size=n_subspace, replace=False)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_subsample(X, y, idx_subspace, idx_obj):\n",
        "        \"\"\"\n",
        "        Возвращает подвыборку по выбранным индексам объектов и признаков\n",
        "        \"\"\"\n",
        "        X_sampled = X[np.ix_(idx_obj, idx_subspace)]\n",
        "        y_sampled = y[idx_obj]\n",
        "        return X_sampled, y_sampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kUI0HufQa7b"
      },
      "source": [
        "# Пример формата входных и выходных данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "t5ObaQ8MQl-e"
      },
      "outputs": [],
      "source": [
        "X = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
        "Y = np.array([1, 2, 3])\n",
        "s = sample(X, 2)\n",
        "\n",
        "bootstrap_indices = s.bootstrap_sample(X)\n",
        "X_sampled, y_sampled = s.get_subsample(X, Y, s.idx_subspace, bootstrap_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kx_-y3ATRl1f",
        "outputId": "8c234f00-a14f-4a9b-fe84-72641f29e3e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Строки, выбранные из исходного массива X\n",
        "bootstrap_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSF8hy3FRmyP",
        "outputId": "7ef58eec-d966-4cb2-d7ea-28daa5226199"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([2, 1])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Столбцы, выбранные из исходного массива X\n",
        "s.idx_subspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiDNFq6zRg8G",
        "outputId": "a384189b-1d8d-4ab7-dc07-f693e5eb05ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[3, 2],\n",
              "       [6, 5],\n",
              "       [9, 8]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Матрица на выходе\n",
        "X_sampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEaXXOO9RiVZ",
        "outputId": "903f178e-4d32-4787-cda9-b0d60d9ffac2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Вектор ответов на выходе\n",
        "y_sampled"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fEZJ19GIl1W"
      },
      "source": [
        "## Примечания\n",
        "\n",
        "1. Не забывайте, что в качестве ответа на задание нужно отправлять именно реализованный класс, соответствующиий [шаблону выше](https://colab.research.google.com/drive/1LoXr0Rwmcivgla2gAzOKuLgh2ISlokvv#scrollTo=juW_Uoo_ic0z&line=5&uniqifier=1).\n",
        "\n",
        "2. Подумайте, что должны возвращать методы bootstrap_sample и random_subspace (одна из функций возвращает индексы строк, другая - индексы столбцов).\n",
        "\n",
        "3. Пример из блокнота не обязан совпадать с входными данными из блокнота. Он дан лишь для проверки алгоритмов в указанном формате.\n",
        "\n",
        "4. Подумайте, в каких реализуемых методах нужен numpy.unique(), а в каких - нет.\n",
        "\n",
        "5. В реализуемых методах запрещается использовать вывод любой информации на экран (в частности, недопустимо использование print())."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7.2. Случайный лес\n",
        "\n",
        "Ваша задача - написать класс `random_forest` для решения задачи классификации на основе датасета Ирисов Фишера (`sklearn.datasets.load_iris`), принимающий на вход конструктора аргументы `n_estimators`, `max_depth`, `subspaces_dim` и `random_state`. описание этих аргументов приведено ниже. У этого класса должны быть определены методы `.fit()` и `.predict()`, а также поле `._estimators`, в котором должен храниться список алгоритмов, используемых в ансамбле.\n",
        "\n",
        "- n_estimators - число деревьев в ансамбле\n",
        "- max_depth - максимальная глубина каждого дерева в ансамбле\n",
        "- subspaces_dim - размерность случайного подпространства для каждого дерева\n",
        "\n",
        "Для создания обучающей подвыборки для каждого из базовых классификаторов, Вы можете воспользоваться классом `sample`, который Вы реализовали в прошлом задании. В случае его использования, не забудьте включить его описание в файл с Вашим решением текущего задания. Мы также предлагаем вам организовать выбор подпространств для каждого дерева посредством заполнения списка `subspace_idx`, в котором будут логироваться выбранные для каждого базового классификатора подпространства.\n",
        "\n",
        "Замечание: в рамках выполнения данного задания запрещено использовать класс `sklearn.ensemble.RandomForestClassifier`. Такой код не пройдёт проверку.\n",
        "\n",
        "Подберите также гиперпараметры, на которых ваш алгоритм получает наилучшее качество (с точки зрения метрики accuracy, доли правильных ответов) на тестовой выборке с параметром `test_size`=0.3, задайте их в виде глобальных переменных N_ESTIMATORS, MAX_DEPTH, SUBSPACE_DIM.\n",
        "\n",
        "Шаблон класса:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Best hyperparameters found through experimentation\n",
        "N_ESTIMATORS = 100\n",
        "MAX_DEPTH = 5\n",
        "SUBSPACE_DIM = 2\n",
        "\n",
        "class sample(object):\n",
        "    def __init__(self, X, n_subspace):\n",
        "        self.idx_subspace = self.random_subspace(X, n_subspace)\n",
        "\n",
        "    def __call__(self, X, y):\n",
        "        idx_obj = self.bootstrap_sample(X)\n",
        "        X_sampled, y_sampled = self.get_subsample(X, y, self.idx_subspace, idx_obj)\n",
        "        return X_sampled, y_sampled\n",
        "\n",
        "    @staticmethod\n",
        "    def bootstrap_sample(X):\n",
        "        n_samples = X.shape[0]\n",
        "        idx = np.random.choice(np.arange(n_samples), size=n_samples, replace=True)\n",
        "        return np.unique(idx)\n",
        "\n",
        "    @staticmethod\n",
        "    def random_subspace(X, n_subspace):\n",
        "        n_features = X.shape[1]\n",
        "        return np.random.choice(np.arange(n_features), size=n_subspace, replace=False)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_subsample(X, y, idx_subspace, idx_obj):\n",
        "        X_sampled = X[np.ix_(idx_obj, idx_subspace)]\n",
        "        y_sampled = y[idx_obj]\n",
        "        return X_sampled, y_sampled\n",
        "\n",
        "class random_forest(object):\n",
        "    def __init__(self, n_estimators: int, max_depth: int, subspaces_dim: int, random_state: int):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.subspaces_dim = subspaces_dim\n",
        "        self.random_state = random_state\n",
        "        self._estimators = []\n",
        "        self.subspace_idx = []\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self._estimators = []\n",
        "        self.subspace_idx = []\n",
        "        \n",
        "        for _ in range(self.n_estimators):\n",
        "            # Create bootstrap sample with random subspace\n",
        "            sampler = sample(X, self.subspaces_dim)\n",
        "            X_sample, y_sample = sampler(X, y)\n",
        "            self.subspace_idx.append(sampler.idx_subspace)\n",
        "            \n",
        "            # Train decision tree\n",
        "            tree = DecisionTreeClassifier(max_depth=self.max_depth, random_state=self.random_state)\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            self._estimators.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.zeros((X.shape[0], len(self._estimators)))\n",
        "        \n",
        "        for i, tree in enumerate(self._estimators):\n",
        "            # Predict using only the features selected for this tree\n",
        "            X_subspace = X[:, self.subspace_idx[i]]\n",
        "            predictions[:, i] = tree.predict(X_subspace)\n",
        "        \n",
        "        # Majority vote\n",
        "        final_predictions = np.apply_along_axis(\n",
        "            lambda x: np.bincount(x.astype(int)).argmax(),\n",
        "            axis=1,\n",
        "            arr=predictions\n",
        "        )\n",
        "        return final_predictions\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == \"__main__\":\n",
        "#     iris = load_iris()\n",
        "#     X, y = iris.data, iris.target\n",
        "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "    \n",
        "#     rf = random_forest(\n",
        "#         n_estimators=N_ESTIMATORS,\n",
        "#         max_depth=MAX_DEPTH,\n",
        "#         subspaces_dim=SUBSPACE_DIM,\n",
        "#         random_state=42\n",
        "#     )\n",
        "#     rf.fit(X_train, y_train)\n",
        "#     y_pred = rf.predict(X_test)\n",
        "    \n",
        "#     print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Примечания\n",
        "\n",
        "1. В данной задаче запрещено использовать библиотеку pandas.\n",
        "\n",
        "2. В реализуемых методах запрещается использовать вывод любой информации на экран (в частности, недопустимо использование print())."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Пример входных и выходных данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 2, 3],\n",
              "       [4, 5, 6],\n",
              "       [7, 8, 9]])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3, 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = random_forest(25, 15, 2, 42)\n",
        "rf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "preds = rf.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "preds"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "vega",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
